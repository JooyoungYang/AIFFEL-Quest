{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8b552c1",
   "metadata": {},
   "source": [
    "### 프로젝트: 뉴스기사 요약해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acc292df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.5\n",
      "2.6.0\n",
      "1.3.3\n",
      "1.2.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "import nltk\n",
    "import tensorflow\n",
    "import summa\n",
    "import pandas as pd\n",
    "\n",
    "print(nltk.__version__)\n",
    "print(tensorflow.__version__)\n",
    "print(pd.__version__)\n",
    "print(version('summa'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "640922c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /aiffel/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import urllib.request\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='bs4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804a0903",
   "metadata": {},
   "source": [
    "#### Step 1. 데이터 수집하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aa54f691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90570</th>\n",
       "      <td>Tripathi's 93 helps RPS rise to third spot in ...</td>\n",
       "      <td>Rising Pune Supergiant defeated Kolkata Knight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87714</th>\n",
       "      <td>Celina Jaitly pregnant with twins again</td>\n",
       "      <td>Actress Celina Jaitly, who is a mother to five...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32679</th>\n",
       "      <td>We did not encourage crime: SC refuses stay on...</td>\n",
       "      <td>Refusing the Centre's petition to stay its Mar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71968</th>\n",
       "      <td>Delhi man arrested for sex assault, murder of ...</td>\n",
       "      <td>The Delhi Police has arrested a 40-year-old ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65421</th>\n",
       "      <td>Complete lack of interest by CBI in Najeeb Ahm...</td>\n",
       "      <td>The Delhi High Court on Monday slammed the CBI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50624</th>\n",
       "      <td>'Plastic road-maker' Rajagopalan Vasudevan win...</td>\n",
       "      <td>Rajagopalan Vasudevan, dubbed 'plastic road-ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13307</th>\n",
       "      <td>WhatsApp India not complying with payment data...</td>\n",
       "      <td>Days after WhatsApp announced a local system t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55164</th>\n",
       "      <td>US terrified by our nuclear force: North Korea</td>\n",
       "      <td>Following the UN Security Council decision to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4853</th>\n",
       "      <td>Ranveer to play Dara Shikoh, Vicky to play Aur...</td>\n",
       "      <td>Actors Ranveer Singh and Vicky Kaushal have re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7003</th>\n",
       "      <td>23-year-old tries to settle fight, gets killed...</td>\n",
       "      <td>A 23-year-old man in Pune was allegedly killed...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               headlines  \\\n",
       "90570  Tripathi's 93 helps RPS rise to third spot in ...   \n",
       "87714            Celina Jaitly pregnant with twins again   \n",
       "32679  We did not encourage crime: SC refuses stay on...   \n",
       "71968  Delhi man arrested for sex assault, murder of ...   \n",
       "65421  Complete lack of interest by CBI in Najeeb Ahm...   \n",
       "50624  'Plastic road-maker' Rajagopalan Vasudevan win...   \n",
       "13307  WhatsApp India not complying with payment data...   \n",
       "55164     US terrified by our nuclear force: North Korea   \n",
       "4853   Ranveer to play Dara Shikoh, Vicky to play Aur...   \n",
       "7003   23-year-old tries to settle fight, gets killed...   \n",
       "\n",
       "                                                    text  \n",
       "90570  Rising Pune Supergiant defeated Kolkata Knight...  \n",
       "87714  Actress Celina Jaitly, who is a mother to five...  \n",
       "32679  Refusing the Centre's petition to stay its Mar...  \n",
       "71968  The Delhi Police has arrested a 40-year-old ma...  \n",
       "65421  The Delhi High Court on Monday slammed the CBI...  \n",
       "50624  Rajagopalan Vasudevan, dubbed 'plastic road-ma...  \n",
       "13307  Days after WhatsApp announced a local system t...  \n",
       "55164  Following the UN Security Council decision to ...  \n",
       "4853   Actors Ranveer Singh and Vicky Kaushal have re...  \n",
       "7003   A 23-year-old man in Pune was allegedly killed...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/sunnysai12345/News_Summary/master/news_summary_more.csv\", filename=\"news_summary_more.csv\")\n",
    "data = pd.read_csv('news_summary_more.csv', encoding='iso-8859-1')\n",
    "\n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fd6fe4",
   "metadata": {},
   "source": [
    "#### Step 2. 데이터 전처리하기 (추상적 요약)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0386ef58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 열에서 중복을 배제한 유일한 샘플의 수 : 98360\n",
      "Summary 열에서 중복을 배제한 유일한 샘플의 수 : 98280\n",
      "전체 샘플수 : 98360\n"
     ]
    }
   ],
   "source": [
    "print('Text 열에서 중복을 배제한 유일한 샘플의 수 :', data['text'].nunique())\n",
    "print('Summary 열에서 중복을 배제한 유일한 샘플의 수 :', data['headlines'].nunique())\n",
    "\n",
    "data.drop_duplicates(subset = ['text'], inplace=True)\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "99987ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "headlines    0\n",
      "text         0\n",
      "dtype: int64\n",
      "전체 샘플수 : 98360\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().sum())\n",
    "\n",
    "data.dropna(axis=0, inplace=True)\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "41b393bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정규화 사전의 수:  120\n",
      "불용어 개수 : 179\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 정규화와 불용어 제거\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "contractions = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}\n",
    "\n",
    "print(\"정규화 사전의 수: \", len(contractions))\n",
    "\n",
    "print('불용어 개수 :', len(stopwords.words('english') ))\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "228d3c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리 함수\n",
    "def preprocess_sentence(sentence, remove_stopwords=True):\n",
    "    sentence = sentence.lower() # 텍스트 소문자화\n",
    "    sentence = BeautifulSoup(sentence, \"lxml\").text # <br />, <a href = ...> 등의 html 태그 제거\n",
    "    sentence = re.sub(r'\\([^)]*\\)', '', sentence) # 괄호로 닫힌 문자열 (...) 제거 Ex) my husband (and myself!) for => my husband for\n",
    "    sentence = re.sub('\"','', sentence) # 쌍따옴표 \" 제거\n",
    "    sentence = ' '.join([contractions[t] if t in contractions else t for t in sentence.split(\" \")]) # 약어 정규화\n",
    "    sentence = re.sub(r\"'s\\b\",\"\", sentence) # 소유격 제거. Ex) roland's -> roland\n",
    "    sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence) # 영어 외 문자(숫자, 특수문자 등) 공백으로 변환\n",
    "    sentence = re.sub('[m]{2,}', 'mm', sentence) # m이 3개 이상이면 2개로 변경. Ex) ummmmmmm yeah -> umm yeah\n",
    "    \n",
    "    # 불용어 제거 (Text)\n",
    "    if remove_stopwords:\n",
    "        tokens = ' '.join(word for word in sentence.split() if not word in stopwords.words('english') if len(word) > 1)\n",
    "    # 불용어 미제거 (Summary)\n",
    "    else:\n",
    "        tokens = ' '.join(word for word in sentence.split() if len(word) > 1)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f93c7ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 전처리 후 결과:  ['saurav kant alumnus upgrad iiit pg program machine learning artificial intelligence sr systems engineer infosys almost years work experience program upgrad degree career support helped transition data scientist tech mahindra salary hike upgrad online power learning powered lakh careers', 'kunal shah credit card bill payment platform cred gave users chance win free food swiggy one year pranav kaushik delhi techie bagged reward spending cred coins users get one cred coin per rupee bill paid used avail rewards brands like ixigo bookmyshow ubereats cult fit', 'new zealand defeated india wickets fourth odi hamilton thursday win first match five match odi series india lost international match rohit sharma captaincy consecutive victories dating back march match witnessed india getting seventh lowest total odi cricket history', 'aegon life iterm insurance plan customers enjoy tax benefits premiums paid save taxes plan provides life cover age years also customers options insure critical illnesses disability accidental death benefit rider life cover age years', 'speaking sexual harassment allegations rajkumar hirani sonam kapoor said known hirani many years true metoo movement get derailed metoo movement always believe woman case need reserve judgment added hirani accused assistant worked sanju']\n"
     ]
    }
   ],
   "source": [
    "# Text를 전처리하고, 결과를 확인하기 위해 상위 5개 출력\n",
    "\n",
    "clean_text = []\n",
    "# 전체 Text 데이터에 대한 전처리 : 10분 이상 시간이 걸릴 수 있습니다. \n",
    "for s in data['text']:\n",
    "    clean_text.append(preprocess_sentence(s))\n",
    "\n",
    "# 전처리 후 출력\n",
    "print(\"Text 전처리 후 결과: \", clean_text[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "90104942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary 전처리 후 결과:  ['upgrad learner switches to career in ml al with salary hike', 'delhi techie wins free food from swiggy for one year on cred', 'new zealand end rohit sharma led india match winning streak', 'aegon life iterm insurance plan helps customers save tax', 'have known hirani for yrs what if metoo claims are not true sonam']\n"
     ]
    }
   ],
   "source": [
    "# Summary 전처리 시에는 불용어 제거를 'False'로 지정\n",
    "\n",
    "clean_summary = []\n",
    "# 전체 Summary 데이터에 대한 전처리 : 5분 이상 시간이 걸릴 수 있습니다. \n",
    "for s in data['headlines']:\n",
    "    clean_summary.append(preprocess_sentence(s, False))\n",
    "\n",
    "print(\"Summary 전처리 후 결과: \", clean_summary[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5c1c261b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Text'] = clean_text\n",
    "data['Summary'] = clean_summary\n",
    "\n",
    "# 빈 값을 Null 값으로 변환\n",
    "data.replace('', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4ecb542a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "headlines    0\n",
      "text         0\n",
      "Text         0\n",
      "Summary      0\n",
      "dtype: int64\n",
      "전체 샘플수 : 98360\n"
     ]
    }
   ],
   "source": [
    "# 빈 샘플을 확인후 제거하기\n",
    "\n",
    "print(data.isnull().sum())\n",
    "\n",
    "data.dropna(axis=0, inplace=True)\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fd5f1b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텍스트의 최소 길이 : 1\n",
      "텍스트의 최대 길이 : 60\n",
      "텍스트의 평균 길이 : 35.09968483123221\n",
      "요약의 최소 길이 : 1\n",
      "요약의 최대 길이 : 16\n",
      "요약의 평균 길이 : 9.299532330215534\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### 훈련데이터와 테스트데이터 나누기\n",
    "\n",
    "# 길이 분포 출력\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text_len = [len(s.split()) for s in data['Text']]\n",
    "summary_len = [len(s.split()) for s in data['Summary']]\n",
    "\n",
    "print('텍스트의 최소 길이 : {}'.format(np.min(text_len)))\n",
    "print('텍스트의 최대 길이 : {}'.format(np.max(text_len)))\n",
    "print('텍스트의 평균 길이 : {}'.format(np.mean(text_len)))\n",
    "print('요약의 최소 길이 : {}'.format(np.min(summary_len)))\n",
    "print('요약의 최대 길이 : {}'.format(np.max(summary_len)))\n",
    "print('요약의 평균 길이 : {}'.format(np.mean(summary_len)))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.boxplot(text_len)\n",
    "plt.title('Text')\n",
    "plt.subplot(1,2,2)\n",
    "plt.boxplot(summary_len)\n",
    "plt.title('Summary')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.title('Text')\n",
    "plt.hist(text_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n",
    "\n",
    "plt.title('Summary')\n",
    "plt.hist(summary_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7d226356",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_max_len = 50\n",
    "summary_max_len = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "35895ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "def below_threshold_len(max_len, nested_list):\n",
    "  cnt = 0\n",
    "  for s in nested_list:\n",
    "    if(len(s.split()) <= max_len):\n",
    "        cnt = cnt + 1\n",
    "  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))))\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "261c3dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 50 이하인 샘플의 비율: 0.9998576657177715\n",
      "전체 샘플 중 길이가 12 이하인 샘플의 비율: 0.9880337535583571\n"
     ]
    }
   ],
   "source": [
    "below_threshold_len(text_max_len, data['Text'])\n",
    "below_threshold_len(summary_max_len,  data['Summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2af0063f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 97169\n"
     ]
    }
   ],
   "source": [
    "# 정해진 길이보다 길면 제외하기\n",
    "\n",
    "data = data[data['Text'].apply(lambda x: len(x.split()) <= text_max_len)]\n",
    "data = data[data['Summary'].apply(lambda x: len(x.split()) <= summary_max_len)]\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3a8815fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "      <th>Text</th>\n",
       "      <th>Summary</th>\n",
       "      <th>decoder_input</th>\n",
       "      <th>decoder_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>upGrad learner switches to career in ML &amp; Al w...</td>\n",
       "      <td>Saurav Kant, an alumnus of upGrad and IIIT-B's...</td>\n",
       "      <td>saurav kant alumnus upgrad iiit pg program mac...</td>\n",
       "      <td>upgrad learner switches to career in ml al wit...</td>\n",
       "      <td>sostoken upgrad learner switches to career in ...</td>\n",
       "      <td>upgrad learner switches to career in ml al wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Delhi techie wins free food from Swiggy for on...</td>\n",
       "      <td>Kunal Shah's credit card bill payment platform...</td>\n",
       "      <td>kunal shah credit card bill payment platform c...</td>\n",
       "      <td>delhi techie wins free food from swiggy for on...</td>\n",
       "      <td>sostoken delhi techie wins free food from swig...</td>\n",
       "      <td>delhi techie wins free food from swiggy for on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New Zealand end Rohit Sharma-led India's 12-ma...</td>\n",
       "      <td>New Zealand defeated India by 8 wickets in the...</td>\n",
       "      <td>new zealand defeated india wickets fourth odi ...</td>\n",
       "      <td>new zealand end rohit sharma led india match w...</td>\n",
       "      <td>sostoken new zealand end rohit sharma led indi...</td>\n",
       "      <td>new zealand end rohit sharma led india match w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aegon life iTerm insurance plan helps customer...</td>\n",
       "      <td>With Aegon Life iTerm Insurance plan, customer...</td>\n",
       "      <td>aegon life iterm insurance plan customers enjo...</td>\n",
       "      <td>aegon life iterm insurance plan helps customer...</td>\n",
       "      <td>sostoken aegon life iterm insurance plan helps...</td>\n",
       "      <td>aegon life iterm insurance plan helps customer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Rahat Fateh Ali Khan denies getting notice for...</td>\n",
       "      <td>Pakistani singer Rahat Fateh Ali Khan has deni...</td>\n",
       "      <td>pakistani singer rahat fateh ali khan denied r...</td>\n",
       "      <td>rahat fateh ali khan denies getting notice for...</td>\n",
       "      <td>sostoken rahat fateh ali khan denies getting n...</td>\n",
       "      <td>rahat fateh ali khan denies getting notice for...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           headlines  \\\n",
       "0  upGrad learner switches to career in ML & Al w...   \n",
       "1  Delhi techie wins free food from Swiggy for on...   \n",
       "2  New Zealand end Rohit Sharma-led India's 12-ma...   \n",
       "3  Aegon life iTerm insurance plan helps customer...   \n",
       "5  Rahat Fateh Ali Khan denies getting notice for...   \n",
       "\n",
       "                                                text  \\\n",
       "0  Saurav Kant, an alumnus of upGrad and IIIT-B's...   \n",
       "1  Kunal Shah's credit card bill payment platform...   \n",
       "2  New Zealand defeated India by 8 wickets in the...   \n",
       "3  With Aegon Life iTerm Insurance plan, customer...   \n",
       "5  Pakistani singer Rahat Fateh Ali Khan has deni...   \n",
       "\n",
       "                                                Text  \\\n",
       "0  saurav kant alumnus upgrad iiit pg program mac...   \n",
       "1  kunal shah credit card bill payment platform c...   \n",
       "2  new zealand defeated india wickets fourth odi ...   \n",
       "3  aegon life iterm insurance plan customers enjo...   \n",
       "5  pakistani singer rahat fateh ali khan denied r...   \n",
       "\n",
       "                                             Summary  \\\n",
       "0  upgrad learner switches to career in ml al wit...   \n",
       "1  delhi techie wins free food from swiggy for on...   \n",
       "2  new zealand end rohit sharma led india match w...   \n",
       "3  aegon life iterm insurance plan helps customer...   \n",
       "5  rahat fateh ali khan denies getting notice for...   \n",
       "\n",
       "                                       decoder_input  \\\n",
       "0  sostoken upgrad learner switches to career in ...   \n",
       "1  sostoken delhi techie wins free food from swig...   \n",
       "2  sostoken new zealand end rohit sharma led indi...   \n",
       "3  sostoken aegon life iterm insurance plan helps...   \n",
       "5  sostoken rahat fateh ali khan denies getting n...   \n",
       "\n",
       "                                      decoder_target  \n",
       "0  upgrad learner switches to career in ml al wit...  \n",
       "1  delhi techie wins free food from swiggy for on...  \n",
       "2  new zealand end rohit sharma led india match w...  \n",
       "3  aegon life iterm insurance plan helps customer...  \n",
       "5  rahat fateh ali khan denies getting notice for...  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 요약 데이터에는 시작 토큰과 종료 토큰을 추가한다.\n",
    "data['decoder_input'] = data['Summary'].apply(lambda x : 'sostoken '+ x)\n",
    "data['decoder_target'] = data['Summary'].apply(lambda x : x + ' eostoken')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8237e97c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "# 인코더의 입력, 디코더의 입력 & 레이블을 다시 Numpy 타입으로 저장하기\n",
    "\n",
    "encoder_input = np.array(data['Text']) # 인코더의 입력\n",
    "decoder_input = np.array(data['decoder_input']) # 디코더의 입력\n",
    "decoder_target = np.array(data['decoder_target']) # 디코더의 레이블\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b63fa601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5756 43075 70952 ... 30842 50139 51749]\n",
      "=3\n",
      "테스트 데이터의 수 : 19433\n",
      "훈련 데이터의 개수 : 77736\n",
      "훈련 레이블의 개수 : 77736\n",
      "테스트 데이터의 개수 : 19433\n",
      "테스트 레이블의 개수 : 19433\n"
     ]
    }
   ],
   "source": [
    "# 훈련/테스트 데이터 분리\n",
    "\n",
    "## encoder_input과 크기/형태가 같은 순서가 섞인 정수 시퀀스 생성\n",
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "print(indices)\n",
    "\n",
    "## 만든 정수 시퀀스를 이용해 데이터의 샘플 순서를 정의\n",
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]\n",
    "print('=3')\n",
    "\n",
    "## 데이터를 8:2 비율로 분리. 전체 데이터 크기에서 0.2를 곱해서 테스트 데이터의 크기를 정한다.\n",
    "n_of_val = int(len(encoder_input)*0.2)\n",
    "print('테스트 데이터의 수 :', n_of_val)\n",
    "\n",
    "## 정의한 테스트 데이터 개수를 이용해 전체 데이터를 split.\n",
    "## : 표시의 위치에 주의!!\n",
    "\n",
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :', len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :', len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :', len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cdac92f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_tokenizer = Tokenizer() # 토크나이저 정의\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 입력된 데이터로부터 단어 집합 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dc0e222d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 69190\n",
      "등장 빈도가 6번 이하인 희귀 단어의 수: 47118\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 22072\n",
      "단어 집합에서 희귀 단어의 비율: 68.09943633473046\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 3.502952960031893\n"
     ]
    }
   ],
   "source": [
    "threshold = 7\n",
    "total_cnt = len(src_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in src_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "16b0478b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "src_vocab = 16000\n",
    "src_tokenizer = Tokenizer(num_words=src_vocab) # 단어 집합의 크기를 16,000으로 제한\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 단어 집합 재생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "48a2f1f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2544, 48, 1, 1015, 14, 2256, 3852, 12152, 126, 6434, 1105, 269, 1072, 650, 2486, 20, 425, 1398, 641, 882, 429, 2768, 429, 312, 1900, 831, 3084, 1156, 2544, 1], [3, 13, 38, 338, 88, 2525, 67, 52, 617, 10219, 3214, 64, 154, 5786, 972, 133, 9, 1, 44, 24, 1194, 835, 3995, 752, 52, 491, 3672, 3879, 142, 258, 177, 666, 934, 3718, 369], [567, 2425, 989, 108, 5609, 131, 458, 252, 367, 1809, 131, 458, 1, 567, 7, 246, 1568, 989, 458, 252, 1380, 91, 345, 989, 252, 567, 893, 2356, 989, 989, 1665, 625, 110, 118, 990]]\n"
     ]
    }
   ],
   "source": [
    "# texts_to_sequences()는 생성된 단어 집합에 기반하여 입력으로 주어진 단어들을 모두 정수로 변환한다(정수인코딩).\n",
    "\n",
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "encoder_input_train = src_tokenizer.texts_to_sequences(encoder_input_train) \n",
    "encoder_input_test = src_tokenizer.texts_to_sequences(encoder_input_test)\n",
    "\n",
    "# 잘 진행되었는지 샘플 출력\n",
    "print(encoder_input_train[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1c8e413e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n",
      "단어 집합(vocabulary)의 크기 : 30025\n",
      "등장 빈도가 4번 이하인 희귀 단어의 수: 18480\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 11545\n",
      "단어 집합에서 희귀 단어의 비율: 61.54870940882597\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 3.9805719288958685\n"
     ]
    }
   ],
   "source": [
    "# Summary 데이터에 대해서도 동일한 작업 수행\n",
    "tar_tokenizer = Tokenizer()\n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
    "print('=3')\n",
    "\n",
    "\n",
    "# tar_tokenizer.word_counts.items()에는 단어와 각 단어의 등장 빈도수가 저장돼 있다. \n",
    "# 이를 통해 등장 빈도수가 5회 미만인 단어들이 이 데이터에서 얼만큼의 비중을 차지하는지 확인해보자.\n",
    "threshold = 5\n",
    "total_cnt = len(tar_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in tar_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2d6e8e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input\n",
      "input  [[1, 1834, 56, 19, 115, 4000, 7222, 4, 1435], [1, 389, 20, 4806, 63, 17, 3458, 16, 38, 7, 318], [1, 253, 496, 173, 5385, 794, 697, 559], [1, 1546, 1835, 3378, 81, 4, 26], [1, 141, 1296, 2058, 2426, 4, 347, 639, 1407, 89]]\n",
      "target\n",
      "decoder  [[1834, 56, 19, 115, 4000, 7222, 4, 1435, 2], [389, 20, 4806, 63, 17, 3458, 16, 38, 7, 318, 2], [253, 496, 173, 5385, 794, 697, 559, 2], [1546, 1835, 3378, 81, 4, 26, 2], [141, 1296, 2058, 2426, 4, 347, 639, 1407, 89, 2]]\n"
     ]
    }
   ],
   "source": [
    "# 이전과 동일하게, 등장 빈도가 4회 이하인 단어들을 제거한다.\n",
    "# 어림잡아 8000을 단어 집합의 크기로 제한한다.\n",
    "\n",
    "tar_vocab = 8000\n",
    "tar_tokenizer = Tokenizer(num_words=tar_vocab) \n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
    "tar_tokenizer.fit_on_texts(decoder_target_train)\n",
    "\n",
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "decoder_input_train = tar_tokenizer.texts_to_sequences(decoder_input_train) \n",
    "decoder_target_train = tar_tokenizer.texts_to_sequences(decoder_target_train)\n",
    "decoder_input_test = tar_tokenizer.texts_to_sequences(decoder_input_test)\n",
    "decoder_target_test = tar_tokenizer.texts_to_sequences(decoder_target_test)\n",
    "\n",
    "# 잘 변환되었는지 확인\n",
    "print('input')\n",
    "print('input ',decoder_input_train[:5])\n",
    "print('target')\n",
    "print('decoder ',decoder_target_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9cacf976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삭제할 훈련 데이터의 개수 : 1\n",
      "삭제할 테스트 데이터의 개수 : 0\n",
      "훈련 데이터의 개수 : 77735\n",
      "훈련 레이블의 개수 : 77735\n",
      "테스트 데이터의 개수 : 19433\n",
      "테스트 레이블의 개수 : 19433\n"
     ]
    }
   ],
   "source": [
    "# 길이가 1인 요약문 삭제\n",
    "\n",
    "drop_train = [index for index, sentence in enumerate(decoder_input_train) if len(sentence) == 1]\n",
    "drop_test = [index for index, sentence in enumerate(decoder_input_test) if len(sentence) == 1]\n",
    "\n",
    "print('삭제할 훈련 데이터의 개수 :', len(drop_train))\n",
    "print('삭제할 테스트 데이터의 개수 :', len(drop_test))\n",
    "\n",
    "encoder_input_train = [sentence for index, sentence in enumerate(encoder_input_train) if index not in drop_train]\n",
    "decoder_input_train = [sentence for index, sentence in enumerate(decoder_input_train) if index not in drop_train]\n",
    "decoder_target_train = [sentence for index, sentence in enumerate(decoder_target_train) if index not in drop_train]\n",
    "\n",
    "encoder_input_test = [sentence for index, sentence in enumerate(encoder_input_test) if index not in drop_test]\n",
    "decoder_input_test = [sentence for index, sentence in enumerate(decoder_input_test) if index not in drop_test]\n",
    "decoder_target_test = [sentence for index, sentence in enumerate(decoder_target_test) if index not in drop_test]\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :', len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :', len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :', len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e2937df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "encoder_input_train = pad_sequences(encoder_input_train, maxlen=text_max_len, padding='post')\n",
    "encoder_input_test = pad_sequences(encoder_input_test, maxlen=text_max_len, padding='post')\n",
    "decoder_input_train = pad_sequences(decoder_input_train, maxlen=summary_max_len, padding='post')\n",
    "decoder_target_train = pad_sequences(decoder_target_train, maxlen=summary_max_len, padding='post')\n",
    "decoder_input_test = pad_sequences(decoder_input_test, maxlen=summary_max_len, padding='post')\n",
    "decoder_target_test = pad_sequences(decoder_target_test, maxlen=summary_max_len, padding='post')\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150134d9",
   "metadata": {},
   "source": [
    "#### Step 3. 어텐션 메커니즘 사용하기 (추상적 요약)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "801171ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "# 인코더 설계 시작\n",
    "embedding_dim = 128\n",
    "hidden_size = 256\n",
    "\n",
    "# 인코더\n",
    "encoder_inputs = Input(shape=(text_max_len,))\n",
    "\n",
    "# 인코더의 임베딩 층\n",
    "enc_emb = Embedding(src_vocab, embedding_dim)(encoder_inputs)\n",
    "\n",
    "# 인코더의 LSTM 1\n",
    "encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4, recurrent_dropout = 0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "# 인코더의 LSTM 2\n",
    "encoder_lstm2 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "# 인코더의 LSTM 3\n",
    "encoder_lstm3 = LSTM(hidden_size, return_state=True, return_sequences=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9cb5012f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "# 디코더 설계\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "# 디코더의 임베딩 층\n",
    "dec_emb_layer = Embedding(tar_vocab, embedding_dim)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 디코더의 LSTM\n",
    "decoder_lstm = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.2)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=[state_h, state_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "970ec35d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 50, 128)      2048000     input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   [(None, 50, 256), (N 394240      embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_5 (LSTM)                   [(None, 50, 256), (N 525312      lstm_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, None, 128)    1024000     input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_6 (LSTM)                   [(None, 50, 256), (N 525312      lstm_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_7 (LSTM)                   [(None, None, 256),  394240      embedding_3[0][0]                \n",
      "                                                                 lstm_6[0][1]                     \n",
      "                                                                 lstm_6[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, None, 8000)   2056000     lstm_7[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 6,967,104\n",
      "Trainable params: 6,967,104\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_outputs) \n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "73b11339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 50, 128)      2048000     input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   [(None, 50, 256), (N 394240      embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_5 (LSTM)                   [(None, 50, 256), (N 525312      lstm_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, None, 128)    1024000     input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_6 (LSTM)                   [(None, 50, 256), (N 525312      lstm_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_7 (LSTM)                   [(None, None, 256),  394240      embedding_3[0][0]                \n",
      "                                                                 lstm_6[0][1]                     \n",
      "                                                                 lstm_6[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AdditiveAttent (None, None, 256)    256         lstm_7[0][0]                     \n",
      "                                                                 lstm_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 512)    0           lstm_7[0][0]                     \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, None, 8000)   4104000     concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 9,015,360\n",
      "Trainable params: 9,015,360\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import AdditiveAttention\n",
    "\n",
    "# 어텐션 층(어텐션 함수)\n",
    "attn_layer = AdditiveAttention(name='attention_layer')\n",
    "\n",
    "# 인코더와 디코더의 모든 time step의 hidden state를 어텐션 층에 전달하고 결과를 리턴\n",
    "attn_out = attn_layer([decoder_outputs, encoder_outputs])\n",
    "\n",
    "\n",
    "# 어텐션의 결과와 디코더의 hidden state들을 연결\n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_concat_input)\n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "09053f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "304/304 [==============================] - 227s 720ms/step - loss: 5.4296 - val_loss: 5.0149\n",
      "Epoch 2/50\n",
      "304/304 [==============================] - 226s 744ms/step - loss: 4.8446 - val_loss: 4.6497\n",
      "Epoch 3/50\n",
      "304/304 [==============================] - 248s 816ms/step - loss: 4.5269 - val_loss: 4.3842\n",
      "Epoch 4/50\n",
      "304/304 [==============================] - 248s 817ms/step - loss: 4.2694 - val_loss: 4.1776\n",
      "Epoch 5/50\n",
      "304/304 [==============================] - 250s 823ms/step - loss: 4.0637 - val_loss: 4.0451\n",
      "Epoch 6/50\n",
      "304/304 [==============================] - 248s 816ms/step - loss: 3.8996 - val_loss: 3.9373\n",
      "Epoch 7/50\n",
      " 12/304 [>.............................] - ETA: 3:43 - loss: 3.7554"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_270/385517651.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rmsprop'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m history = model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n\u001b[0m\u001b[1;32m      4\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mencoder_input_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_input_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_target_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m           batch_size=256, callbacks=[es], epochs=50)\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1187\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    433\u001b[0m     \"\"\"\n\u001b[1;32m    434\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    293\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    313\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1028\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1029\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    510\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \"\"\"\n\u001b[1;32m   1093\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1094\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1095\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1058\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
    "es = EarlyStopping(monitor='val_loss', patience=2, verbose=1)\n",
    "history = model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n",
    "          validation_data=([encoder_input_test, decoder_input_test], decoder_target_test), \\\n",
    "          batch_size=256, callbacks=[es], epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41aa9869",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec7234e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44ac9ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1498d754",
   "metadata": {},
   "source": [
    "#### Step 4. 실제 결과와 요약문 비교하기 (추상적 요약)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170ebe13",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_index_to_word = src_tokenizer.index_word # 원문 단어 집합에서 정수 -> 단어를 얻음\n",
    "tar_word_to_index = tar_tokenizer.word_index # 요약 단어 집합에서 단어 -> 정수를 얻음\n",
    "tar_index_to_word = tar_tokenizer.index_word # 요약 단어 집합에서 정수 -> 단어를 얻음\n",
    "\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae254b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 설계\n",
    "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# 이전 시점의 상태들을 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(hidden_size,))\n",
    "decoder_state_input_c = Input(shape=(hidden_size,))\n",
    "\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용. 이는 뒤의 함수 decode_sequence()에 구현\n",
    "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음.\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc180b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어텐션 함수\n",
    "decoder_hidden_state_input = Input(shape=(text_max_len, hidden_size))\n",
    "attn_out_inf = attn_layer([decoder_outputs2, decoder_hidden_state_input])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_outputs2 = decoder_softmax_layer(decoder_inf_concat) \n",
    "\n",
    "# 최종 디코더 모델\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])\n",
    "\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c25ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "\n",
    "     # <SOS>에 해당하는 토큰 생성\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = tar_word_to_index['sostoken']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition: # stop_condition이 True가 될 때까지 루프 반복\n",
    "\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = tar_index_to_word[sampled_token_index]\n",
    "\n",
    "        if (sampled_token!='eostoken'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        #  <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_token == 'eostoken'  or len(decoded_sentence.split()) >= (summary_max_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 길이가 1인 타겟 시퀀스를 업데이트\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 상태를 업데이트 합니다.\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db33413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2text(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if (i!=0):\n",
    "            temp = temp + src_index_to_word[i]+' '\n",
    "    return temp\n",
    "\n",
    "# 요약문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2summary(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if ((i!=0 and i!=tar_word_to_index['sostoken']) and i!=tar_word_to_index['eostoken']):\n",
    "            temp = temp + tar_index_to_word[i] + ' '\n",
    "    return temp\n",
    "\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50636670",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50, 100):\n",
    "    print(\"원문 :\", seq2text(encoder_input_test[i]))\n",
    "    print(\"실제 요약 :\", seq2summary(decoder_input_test[i]))\n",
    "    print(\"예측 요약 :\", decode_sequence(encoder_input_test[i].reshape(1, text_max_len)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77759de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b10485d6",
   "metadata": {},
   "source": [
    "#### Step 5. Summa을 이용해서 추출적 요약해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd6a25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from summa.summarizer import summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dda6ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = requests.get('http://rare-technologies.com/the_matrix_synopsis.txt').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb42685",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text[:1500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ef266b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Summary:')\n",
    "print(summarize(text, ratio=0.005))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54beb772",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Summary:')\n",
    "print(summarize(text, ratio=0.005, split=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c774bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Summary:')\n",
    "print(summarize(text, words=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a815d2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dc72d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3c304c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
